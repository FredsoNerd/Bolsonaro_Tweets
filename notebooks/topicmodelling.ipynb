{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelagem de T√≥picos\n",
    "\n",
    "S√£o poucas as quantidades de modelos que podemos aplicar na maneira que os nossos dados se encontram neste exato momento. Com isso, para que tenhamos mais vari√°veis quantitativas que ajudam na an√°lise, o intuito √© dividir os tweets da fam√≠lia Bolsonaro em t√≥picos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vamos usar diversos recursos do nltk, vale a pena baixar todo seu conte√∫do (uma aba vai abrir e √© s√≥ clicar em baixar tudo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando a Document Term Matrix\n",
    "\n",
    "Usando as stop words em portugu√™s obtidas no site https://gist.github.com/alopes/5358189, podemos limpar nossos textos dos tweets de modo a transform√°-los em uma Document Term Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>media_type</th>\n",
       "      <th>status_reply</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>weekday</th>\n",
       "      <th>has_hashtags</th>\n",
       "      <th>has_mentions</th>\n",
       "      <th>has_media</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-27 20:51:13+00:00</th>\n",
       "      <td>-Edif√≠cio Joelma/SP, 1974.\\n\\n-Sgt CASSANIGA s...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>video</td>\n",
       "      <td>0</td>\n",
       "      <td>jairbolsonaro</td>\n",
       "      <td>3154</td>\n",
       "      <td>16202</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-27 11:10:36+00:00</th>\n",
       "      <td>- √Ågua para quem tem sede.\\n- Liberdade para u...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>video</td>\n",
       "      <td>0</td>\n",
       "      <td>jairbolsonaro</td>\n",
       "      <td>8101</td>\n",
       "      <td>37357</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-26 20:18:19+00:00</th>\n",
       "      <td>@tarcisiogdf @MInfraestrutura ü§ùüáßüá∑, Ministro!</td>\n",
       "      <td>None</td>\n",
       "      <td>tarcisiogdf/MInfraestrutura</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>jairbolsonaro</td>\n",
       "      <td>1074</td>\n",
       "      <td>16840</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-26 15:40:39+00:00</th>\n",
       "      <td>2- @MinEconomia @MinCidadania @onyxlorenzoni @...</td>\n",
       "      <td>None</td>\n",
       "      <td>MinEconomia/MinCidadania/onyxlorenzoni/MEC_Com...</td>\n",
       "      <td>photo</td>\n",
       "      <td>1</td>\n",
       "      <td>jairbolsonaro</td>\n",
       "      <td>1337</td>\n",
       "      <td>6383</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-26 15:39:47+00:00</th>\n",
       "      <td>1- Acompanhe as redes sociais! @secomvc @fabio...</td>\n",
       "      <td>None</td>\n",
       "      <td>secomvc/fabiofaria5555/tarcisiogdf/MInfraestru...</td>\n",
       "      <td>photo</td>\n",
       "      <td>0</td>\n",
       "      <td>jairbolsonaro</td>\n",
       "      <td>3287</td>\n",
       "      <td>14836</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   full_text  \\\n",
       "date                                                                           \n",
       "2020-07-27 20:51:13+00:00  -Edif√≠cio Joelma/SP, 1974.\\n\\n-Sgt CASSANIGA s...   \n",
       "2020-07-27 11:10:36+00:00  - √Ågua para quem tem sede.\\n- Liberdade para u...   \n",
       "2020-07-26 20:18:19+00:00       @tarcisiogdf @MInfraestrutura ü§ùüáßüá∑, Ministro!   \n",
       "2020-07-26 15:40:39+00:00  2- @MinEconomia @MinCidadania @onyxlorenzoni @...   \n",
       "2020-07-26 15:39:47+00:00  1- Acompanhe as redes sociais! @secomvc @fabio...   \n",
       "\n",
       "                          hashtags  \\\n",
       "date                                 \n",
       "2020-07-27 20:51:13+00:00     None   \n",
       "2020-07-27 11:10:36+00:00     None   \n",
       "2020-07-26 20:18:19+00:00     None   \n",
       "2020-07-26 15:40:39+00:00     None   \n",
       "2020-07-26 15:39:47+00:00     None   \n",
       "\n",
       "                                                               user_mentions  \\\n",
       "date                                                                           \n",
       "2020-07-27 20:51:13+00:00                                               None   \n",
       "2020-07-27 11:10:36+00:00                                               None   \n",
       "2020-07-26 20:18:19+00:00                        tarcisiogdf/MInfraestrutura   \n",
       "2020-07-26 15:40:39+00:00  MinEconomia/MinCidadania/onyxlorenzoni/MEC_Com...   \n",
       "2020-07-26 15:39:47+00:00  secomvc/fabiofaria5555/tarcisiogdf/MInfraestru...   \n",
       "\n",
       "                          media_type  status_reply           name  \\\n",
       "date                                                                \n",
       "2020-07-27 20:51:13+00:00      video             0  jairbolsonaro   \n",
       "2020-07-27 11:10:36+00:00      video             0  jairbolsonaro   \n",
       "2020-07-26 20:18:19+00:00        NaN             1  jairbolsonaro   \n",
       "2020-07-26 15:40:39+00:00      photo             1  jairbolsonaro   \n",
       "2020-07-26 15:39:47+00:00      photo             0  jairbolsonaro   \n",
       "\n",
       "                           retweet_count  favorite_count  year  month  day  \\\n",
       "date                                                                         \n",
       "2020-07-27 20:51:13+00:00           3154           16202  2020      7   27   \n",
       "2020-07-27 11:10:36+00:00           8101           37357  2020      7   27   \n",
       "2020-07-26 20:18:19+00:00           1074           16840  2020      7   26   \n",
       "2020-07-26 15:40:39+00:00           1337            6383  2020      7   26   \n",
       "2020-07-26 15:39:47+00:00           3287           14836  2020      7   26   \n",
       "\n",
       "                           hour  minute  weekday  has_hashtags  has_mentions  \\\n",
       "date                                                                           \n",
       "2020-07-27 20:51:13+00:00    20      51        0             0             0   \n",
       "2020-07-27 11:10:36+00:00    11      10        0             0             0   \n",
       "2020-07-26 20:18:19+00:00    20      18        6             0             1   \n",
       "2020-07-26 15:40:39+00:00    15      40        6             0             1   \n",
       "2020-07-26 15:39:47+00:00    15      39        6             0             1   \n",
       "\n",
       "                           has_media  \n",
       "date                                  \n",
       "2020-07-27 20:51:13+00:00          1  \n",
       "2020-07-27 11:10:36+00:00          1  \n",
       "2020-07-26 20:18:19+00:00          1  \n",
       "2020-07-26 15:40:39+00:00          1  \n",
       "2020-07-26 15:39:47+00:00          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeys_data = pd.read_csv(\"../../data/tweets/preprocessed_tweets.csv\", sep=\"~\", index_col=0)\n",
    "tweeys_data[\"date\"] = pd.to_datetime(tweeys_data[\"date\"])\n",
    "tweeys_data.set_index(\"date\", inplace=True)\n",
    "tweeys_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-Edif√≠cio Joelma/SP, 1974.\\n\\n-Sgt CASSANIGA salta de helic√≥ptero da FAB no terra√ßo do edif√≠cio em chamas para salvar vidas, em uma das maiores tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- √Ågua para quem tem sede.\\n- Liberdade para um povo. \\n- Brasil acima de tudo, Deus acima de todos!\\n- BOM DIA.\\n\\n. YouTube: https://t.co/eS5aHQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@tarcisiogdf @MInfraestrutura ü§ùüáßüá∑, Ministro!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2- @MinEconomia @MinCidadania @onyxlorenzoni @MEC_Comunicacao @ItamaratyGovBr @ernestofaraujo https://t.co/WVf6V7pqzC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1- Acompanhe as redes sociais! @secomvc @fabiofaria5555 @tarcisiogdf @MInfraestrutura @MinEconomia @minsaude @Mapa_Brasil @TerezaCrisMS @DHumanosB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                    text\n",
       "0  -Edif√≠cio Joelma/SP, 1974.\\n\\n-Sgt CASSANIGA salta de helic√≥ptero da FAB no terra√ßo do edif√≠cio em chamas para salvar vidas, em uma das maiores tr...\n",
       "1  - √Ågua para quem tem sede.\\n- Liberdade para um povo. \\n- Brasil acima de tudo, Deus acima de todos!\\n- BOM DIA.\\n\\n. YouTube: https://t.co/eS5aHQ...\n",
       "2                                                                                                           @tarcisiogdf @MInfraestrutura ü§ùüáßüá∑, Ministro!\n",
       "3                                  2- @MinEconomia @MinCidadania @onyxlorenzoni @MEC_Comunicacao @ItamaratyGovBr @ernestofaraujo https://t.co/WVf6V7pqzC\n",
       "4  1- Acompanhe as redes sociais! @secomvc @fabiofaria5555 @tarcisiogdf @MInfraestrutura @MinEconomia @minsaude @Mapa_Brasil @TerezaCrisMS @DHumanosB..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth',150)\n",
    "initial_data = pd.DataFrame(tweeys_data['full_text'].values,index=range(0,len(tweeys_data)),columns=['text'])\n",
    "initial_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpando um pouco nosso texto de cada tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>edificio joelmasp  cassaniga salta de helicoptero da fab no terraco do edificio em chamas para salvar vidas em uma das maiores tragedias na histor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agua para quem tem sede liberdade para um povo  brasil acima de tudo deus acima de todos bom dia youtube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tarcisiogdf minfraestrutura  ministro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mineconomia mincidadania onyxlorenzoni meccomunicacao itamaratygovbr ernestofaraujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acompanhe as redes sociais secomvc  tarcisiogdf minfraestrutura mineconomia minsaude mapabrasil terezacrisms dhumanosbrasil damaresalves</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                    text\n",
       "0  edificio joelmasp  cassaniga salta de helicoptero da fab no terraco do edificio em chamas para salvar vidas em uma das maiores tragedias na histor...\n",
       "1                                             agua para quem tem sede liberdade para um povo  brasil acima de tudo deus acima de todos bom dia youtube  \n",
       "2                                                                                                                  tarcisiogdf minfraestrutura  ministro\n",
       "3                                                                   mineconomia mincidadania onyxlorenzoni meccomunicacao itamaratygovbr ernestofaraujo \n",
       "4              acompanhe as redes sociais secomvc  tarcisiogdf minfraestrutura mineconomia minsaude mapabrasil terezacrisms dhumanosbrasil damaresalves "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower() # texto min√∫sculo\n",
    "    text = re.sub('[^A-z√Ä-√∫0-9 ]', '', text) # manter alfanum√©ricos e espa√ßo\n",
    "    text = re.sub('\\w*\\d\\w*', '', text) # remover qualquer palavra que contenha numeros\n",
    "    text = re.sub('\\w*https?\\w*', '', text) # remover urls\n",
    "    text = ''.join(ch for ch in unicodedata.normalize('NFKD', text) \n",
    "        if not unicodedata.combining(ch))   # remover acentos\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # remover pontua√ß√µes esquisitas\n",
    "    return text\n",
    "\n",
    "clean_data = pd.DataFrame(initial_data.text.apply(lambda x: clean_text(x)))\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando a Document Term Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12824</th>\n",
       "      <th>12825</th>\n",
       "      <th>12826</th>\n",
       "      <th>12827</th>\n",
       "      <th>12828</th>\n",
       "      <th>12829</th>\n",
       "      <th>12830</th>\n",
       "      <th>12831</th>\n",
       "      <th>12832</th>\n",
       "      <th>12833</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aacd</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aao</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aassibarreto</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abaete</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 12834 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0      1      2      3      4      5      6      7      8      \\\n",
       "aacd              0      0      0      0      0      0      0      0      0   \n",
       "aao               0      0      0      0      0      0      0      0      0   \n",
       "aassibarreto      0      0      0      0      0      0      0      0      0   \n",
       "ab                0      0      0      0      0      0      0      0      0   \n",
       "abaete            0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "              9      ...  12824  12825  12826  12827  12828  12829  12830  \\\n",
       "aacd              0  ...      0      0      0      0      0      0      0   \n",
       "aao               0  ...      0      0      0      0      0      0      0   \n",
       "aassibarreto      0  ...      0      0      0      0      0      0      0   \n",
       "ab                0  ...      0      0      0      0      0      0      0   \n",
       "abaete            0  ...      0      0      0      0      0      0      0   \n",
       "\n",
       "              12831  12832  12833  \n",
       "aacd              0      0      0  \n",
       "aao               0      0      0  \n",
       "aassibarreto      0      0      0  \n",
       "ab                0      0      0  \n",
       "abaete            0      0      0  \n",
       "\n",
       "[5 rows x 12834 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_stop_words = np.array([])\n",
    "# stopwords.txt √© o arquivo que se encontra no link no come√ßo da subse√ß√£o\n",
    "with open(\"../../data/stopwords.txt\",encoding=\"utf-8\") as file:\n",
    "    line = file.readline()\n",
    "    while line != '':\n",
    "        line = re.sub('\\\\n$| $', '', line)\n",
    "        pt_stop_words = np.append(pt_stop_words,line)\n",
    "        line = file.readline()\n",
    "pt_stop_words = [clean_text(pt_stop_words[i]) for i in range(0,len(pt_stop_words))]\n",
    "pt_stop_words = list(set(pt_stop_words))\n",
    "\n",
    "cv = text.CountVectorizer(stop_words = text.ENGLISH_STOP_WORDS.union(pt_stop_words))\n",
    "data_cv = cv.fit_transform(clean_data.values.ravel())\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_dtm.index = clean_data.index\n",
    "tdm = data_dtm.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando Topic Modelling (tentativa 1)\n",
    "\n",
    "Com a nossa Document Term Matrix (transposta devido √† entrada da fun√ß√£o a seguir), podemos usar a biblioteca Gensim para criar um modelo de Latent Dirichlet Allocation (LDA) e obter os nossos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colocando a Term Document Matrix em um novo formato gensim, de df --> sparse matrix --> gensim corpus\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim tamb√©m precisa de um dicion√°rio com todos os termos e suas respectivas posi√ß√µes na Term Document Matrix\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos o corpus (Term Document Matrix) e o id2word (dicion√°rio de localiza√ß√£o: termo), precisamos especificar dois outros par√¢metros - o n√∫mero de t√≥picos e o n√∫mero de passos. Inicialmente vamos testar com $4$, $6$ e $10$ t√≥picos juntamente com $10$ passos e ver se os resultados fazem sentido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.019*\"rt\" + 0.012*\"jairbolsonaro\" + 0.011*\"presidente\" + 0.010*\"brasil\" + 0.010*\"bolsonaro\" + 0.008*\"todos\" + 0.006*\"dia\" + 0.005*\"sempre\" + 0.005*\"tudo\" + 0.005*\"deus\"'),\n",
       " (1,\n",
       "  '0.016*\"rt\" + 0.006*\"sobre\" + 0.006*\"bolsonarosp\" + 0.006*\"rio\" + 0.005*\"jairbolsonaro\" + 0.004*\"bolsonaro\" + 0.004*\"presidente\" + 0.004*\"prudencia\" + 0.004*\"sofisticacao\" + 0.004*\"brasil\"'),\n",
       " (2,\n",
       "  '0.015*\"governo\" + 0.012*\"brasil\" + 0.008*\"milhoes\" + 0.008*\"bolsonaro\" + 0.006*\"rt\" + 0.006*\"mil\" + 0.005*\"ano\" + 0.004*\"bilhoes\" + 0.004*\"federal\" + 0.004*\"pais\"'),\n",
       " (3,\n",
       "  '0.011*\"rt\" + 0.007*\"bolsonaro\" + 0.007*\"esquerda\" + 0.006*\"ai\" + 0.006*\"pra\" + 0.005*\"pt\" + 0.005*\"contra\" + 0.003*\"pode\" + 0.003*\"fakenews\" + 0.003*\"sempre\"')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agora que j√° temos o corpus (Term Document Matrix) e id2word (dicion√°rio de localiza√ß√£o: termo),\n",
    "# precisamos especificar tamb√©m dois outros par√¢metros - o n√∫mero de t√≥picos e de passos\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=10, random_state=42)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.027*\"rt\" + 0.015*\"jairbolsonaro\" + 0.013*\"presidente\" + 0.009*\"bolsonaro\" + 0.007*\"sempre\" + 0.006*\"abraco\" + 0.006*\"dia\" + 0.006*\"brasil\" + 0.005*\"verdade\" + 0.005*\"tudo\"'),\n",
       " (1,\n",
       "  '0.024*\"rt\" + 0.016*\"bolsonarosp\" + 0.010*\"sobre\" + 0.010*\"bolsonaro\" + 0.009*\"presidente\" + 0.006*\"jairbolsonaro\" + 0.006*\"agora\" + 0.006*\"hoje\" + 0.005*\"live\" + 0.004*\"claro\"'),\n",
       " (2,\n",
       "  '0.011*\"bolsonaro\" + 0.009*\"rt\" + 0.008*\"contra\" + 0.008*\"presidente\" + 0.006*\"fake\" + 0.005*\"news\" + 0.005*\"sobre\" + 0.004*\"pt\" + 0.004*\"brasil\" + 0.004*\"esquerda\"'),\n",
       " (3,\n",
       "  '0.012*\"rt\" + 0.010*\"pra\" + 0.005*\"prudencia\" + 0.005*\"sofisticacao\" + 0.005*\"odio\" + 0.005*\"bolsonarosp\" + 0.004*\"politicos\" + 0.004*\"esquerda\" + 0.004*\"jornalista\" + 0.004*\"bolsonaro\"'),\n",
       " (4,\n",
       "  '0.019*\"brasil\" + 0.014*\"governo\" + 0.009*\"bolsonaro\" + 0.007*\"pais\" + 0.007*\"ano\" + 0.005*\"todos\" + 0.005*\"rt\" + 0.005*\"maior\" + 0.005*\"ai\" + 0.005*\"jairbolsonaro\"'),\n",
       " (5,\n",
       "  '0.015*\"milhoes\" + 0.012*\"governo\" + 0.011*\"mil\" + 0.009*\"programa\" + 0.009*\"saude\" + 0.007*\"govbr\" + 0.006*\"bilhoes\" + 0.006*\"rt\" + 0.006*\"municipios\" + 0.006*\"narrativa\"')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda2 = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=6, passes=10, random_state=42)\n",
    "lda2.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.055*\"rt\" + 0.041*\"jairbolsonaro\" + 0.019*\"presidente\" + 0.012*\"abraco\" + 0.010*\"carlosbolsonaro\" + 0.009*\"nunca\" + 0.009*\"bolsonaro\" + 0.009*\"hoje\" + 0.008*\"liberdade\" + 0.008*\"ver\"'),\n",
       " (1,\n",
       "  '0.018*\"rio\" + 0.018*\"tarcisiogdf\" + 0.017*\"minfraestrutura\" + 0.009*\"bolsonaro\" + 0.009*\"sociais\" + 0.008*\"redes\" + 0.007*\"rt\" + 0.007*\"sobre\" + 0.007*\"obras\" + 0.007*\"janeiro\"'),\n",
       " (2,\n",
       "  '0.017*\"bolsonaro\" + 0.014*\"presidente\" + 0.014*\"rt\" + 0.010*\"contra\" + 0.007*\"fake\" + 0.007*\"qualquer\" + 0.007*\"pode\" + 0.007*\"sobre\" + 0.007*\"governo\" + 0.006*\"jairbolsonaro\"'),\n",
       " (3,\n",
       "  '0.018*\"rt\" + 0.017*\"pra\" + 0.014*\"arthurweint\" + 0.012*\"congresso\" + 0.009*\"bolsonaro\" + 0.008*\"pouco\" + 0.008*\"quanto\" + 0.006*\"projeto\" + 0.006*\"bolsonarosp\" + 0.005*\"mundo\"'),\n",
       " (4,\n",
       "  '0.025*\"brasil\" + 0.014*\"todos\" + 0.011*\"dia\" + 0.011*\"deus\" + 0.011*\"pais\" + 0.010*\"presidente\" + 0.009*\"tudo\" + 0.008*\"sempre\" + 0.008*\"grande\" + 0.007*\"vai\"'),\n",
       " (5,\n",
       "  '0.016*\"narrativa\" + 0.013*\"youtube\" + 0.011*\"link\" + 0.010*\"educacao\" + 0.009*\"meccomunicacao\" + 0.008*\"brasil\" + 0.008*\"abrahamweint\" + 0.008*\"ensino\" + 0.007*\"linha\" + 0.007*\"dinheiro\"'),\n",
       " (6,\n",
       "  '0.008*\"cara\" + 0.007*\"combate\" + 0.007*\"produtos\" + 0.006*\"importacao\" + 0.006*\"saritacoelho\" + 0.005*\"mineconomia\" + 0.005*\"criancas\" + 0.005*\"governo\" + 0.004*\"livro\" + 0.004*\"medicos\"'),\n",
       " (7,\n",
       "  '0.023*\"milhoes\" + 0.023*\"governo\" + 0.016*\"mil\" + 0.011*\"saude\" + 0.010*\"govbr\" + 0.010*\"estados\" + 0.010*\"mdregionalbr\" + 0.010*\"acoes\" + 0.010*\"municipios\" + 0.010*\"federal\"'),\n",
       " (8,\n",
       "  '0.018*\"ano\" + 0.017*\"governo\" + 0.011*\"bolsonaro\" + 0.008*\"economia\" + 0.007*\"mes\" + 0.007*\"periodo\" + 0.007*\"rt\" + 0.007*\"maior\" + 0.006*\"passado\" + 0.006*\"meses\"'),\n",
       " (9,\n",
       "  '0.026*\"rt\" + 0.015*\"brasil\" + 0.014*\"bolsonaro\" + 0.014*\"bolsonarosp\" + 0.009*\"pt\" + 0.008*\"ai\" + 0.007*\"lula\" + 0.006*\"governo\" + 0.006*\"anos\" + 0.005*\"falar\"')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda3 = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=10, passes=10, random_state=42)\n",
    "lda3.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados s√£o interessantes, mas ainda confusos devido a algumas outras stop words e palavras. Realizaremos a mesma an√°lise agora deixando apenas substantivos e adjetivos (e removendo algumas stop words extras)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando Topic Modelling (tentativa 2)\n",
    "\n",
    "Para que o nosso modelo se torne mais preciso para nossos objetivos, podemos adicionar algumas stop_words identificadas nos grupos de t√≥picos acima e tamb√©m filtrar nossas palavras para apenas substantivos e adjetivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>edificio joelmasp cassaniga salta da fab terraco chamas para salvar uma das maiores historia youtube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agua para quem tem sede para um povo brasil acima deus acima bom dia youtube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tarcisiogdf minfraestrutura ministro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mineconomia mincidadania onyxlorenzoni meccomunicacao itamaratygovbr ernestofaraujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acompanhe redes secomvc tarcisiogdf minfraestrutura mineconomia mapabrasil terezacrisms damaresalves</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   text\n",
       "0  edificio joelmasp cassaniga salta da fab terraco chamas para salvar uma das maiores historia youtube\n",
       "1                          agua para quem tem sede para um povo brasil acima deus acima bom dia youtube\n",
       "2                                                                  tarcisiogdf minfraestrutura ministro\n",
       "3                   mineconomia mincidadania onyxlorenzoni meccomunicacao itamaratygovbr ernestofaraujo\n",
       "4  acompanhe redes secomvc tarcisiogdf minfraestrutura mineconomia mapabrasil terezacrisms damaresalves"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Algumas stop words comuns nos tweets\n",
    "add_stop_words = ['pra','ai','rt', 'fazem', 'aqui', 'entao', 'vamos', 'vai', 'onde']\n",
    "\n",
    "# Fun√ß√£o que retorna substantivo e adjetivo\n",
    "def nouns_adj(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns and adjectives.'''\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = nltk.word_tokenize(text,language='portuguese')\n",
    "    nouns_adj = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun_adj(pos)] \n",
    "    return ' '.join(nouns_adj)\n",
    "\n",
    "nouns_adj_data = pd.DataFrame(clean_data.text.apply(lambda x: nouns_adj(x)))\n",
    "nouns_adj_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_new = text.CountVectorizer(stop_words = text.ENGLISH_STOP_WORDS.union(pt_stop_words+add_stop_words))\n",
    "data_cv_new = cv_new.fit_transform(nouns_adj_data.values.ravel())\n",
    "data_dtm_new = pd.DataFrame(data_cv_new.toarray(), columns=cv_new.get_feature_names())\n",
    "data_dtm_new.index = nouns_adj_data.index\n",
    "tdm_new = data_dtm_new.transpose()\n",
    "sparse_counts_new = scipy.sparse.csr_matrix(tdm_new)\n",
    "\n",
    "# Criando o corpus do Gensim\n",
    "corpus_new = matutils.Sparse2Corpus(sparse_counts_new)\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2word_new = dict((v, k) for k, v in cv_new.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.016*\"news\" + 0.012*\"brasil\" + 0.012*\"fake\" + 0.008*\"sobre\" + 0.008*\"folha\" + 0.006*\"eua\" + 0.006*\"jairbolsonaro\" + 0.006*\"entrevista\" + 0.006*\"renovamidia\" + 0.006*\"tv\"'),\n",
       " (1,\n",
       "  '0.012*\"dia\" + 0.011*\"verdade\" + 0.011*\"presidente\" + 0.011*\"abraco\" + 0.011*\"bolsonaro\" + 0.009*\"todos\" + 0.009*\"bom\" + 0.008*\"grande\" + 0.007*\"narrativa\" + 0.007*\"brasil\"'),\n",
       " (2,\n",
       "  '0.029*\"brasil\" + 0.011*\"todos\" + 0.010*\"deus\" + 0.008*\"parabens\" + 0.007*\"pais\" + 0.007*\"jairbolsonaro\" + 0.007*\"esquerda\" + 0.007*\"arthurweint\" + 0.006*\"bem\" + 0.005*\"dar\"'),\n",
       " (3,\n",
       "  '0.012*\"bolsonaro\" + 0.010*\"jairbolsonaro\" + 0.009*\"boa\" + 0.008*\"brasil\" + 0.008*\"rio\" + 0.007*\"presidente\" + 0.007*\"pode\" + 0.006*\"falar\" + 0.006*\"querem\" + 0.006*\"pt\"'),\n",
       " (4,\n",
       "  '0.025*\"jairbolsonaro\" + 0.019*\"minfraestrutura\" + 0.016*\"tarcisiogdf\" + 0.011*\"youtube\" + 0.010*\"alguem\" + 0.009*\"dias\" + 0.008*\"exercitooficial\" + 0.007*\"govbr\" + 0.007*\"link\" + 0.006*\"brazil\"'),\n",
       " (5,\n",
       "  '0.014*\"brasil\" + 0.010*\"jairbolsonaro\" + 0.009*\"mineconomia\" + 0.007*\"semana\" + 0.007*\"presidente\" + 0.007*\"meccomunicacao\" + 0.006*\"acoes\" + 0.006*\"redes\" + 0.005*\"ernestofaraujo\" + 0.005*\"detalhes\"'),\n",
       " (6,\n",
       "  '0.015*\"bolsonarosp\" + 0.013*\"diz\" + 0.013*\"conexaopolitica\" + 0.011*\"carlosbolsonaro\" + 0.007*\"portimeubr\" + 0.007*\"video\" + 0.005*\"presidencia\" + 0.005*\"acha\" + 0.005*\"comum\" + 0.005*\"jairbolsonaro\"'),\n",
       " (7,\n",
       "  '0.021*\"bolsonaro\" + 0.008*\"jair\" + 0.007*\"contra\" + 0.007*\"sempre\" + 0.006*\"politica\" + 0.006*\"claro\" + 0.006*\"doria\" + 0.005*\"culpa\" + 0.005*\"seguem\" + 0.005*\"pessoas\"'),\n",
       " (8,\n",
       "  '0.017*\"midia\" + 0.016*\"presidente\" + 0.014*\"bolsonaro\" + 0.013*\"parte\" + 0.010*\"imprensa\" + 0.010*\"jairbolsonaro\" + 0.009*\"tudo\" + 0.008*\"contra\" + 0.008*\"ta\" + 0.008*\"democracia\"'),\n",
       " (9,\n",
       "  '0.022*\"governo\" + 0.016*\"milhoes\" + 0.013*\"bolsonaro\" + 0.010*\"federal\" + 0.010*\"bilhoes\" + 0.009*\"ano\" + 0.009*\"municipios\" + 0.008*\"brasil\" + 0.008*\"maior\" + 0.007*\"mil\"')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Teste final com 10 t√≥picos\n",
    "lda6 = models.LdaModel(corpus=corpus_new, num_topics=10, id2word=id2word_new, passes=20, random_state=42)\n",
    "lda6.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, os assuntos principais dos tweets de cada grupo de t√≥picos se envolvem em torno de:\n",
    "\n",
    "0. Fake news e m√≠dia internacional;\n",
    "1. Sauda√ß√µes di√°rias; \n",
    "2. Parabeniza√ß√µes;\n",
    "3. Cr√≠ticas √† esquerda;\n",
    "4. Infraestrutura e ex√©rcito;\n",
    "5. Economia e comunica√ß√£o;\n",
    "6. Opini√µes sobre not√≠cias;\n",
    "7. Direcionados ao governador de SP Jo√£o Doria;\n",
    "8. Oposi√ß√£o da m√≠dia;\n",
    "9. Relacionados com munic√≠pios menores;\n",
    "\n",
    "Claro que todas essas afirma√ß√µes acima s√£o completamente qualitativas.\n",
    "\n",
    "Colocando no nosso dataframe a classifica√ß√£o de t√≥picos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_transformed = lda6[corpus_new]\n",
    "topics = []\n",
    "for tweetTopics in corpus_transformed:\n",
    "    maxValue = 0\n",
    "    rightTopic = 0\n",
    "    for topic,value in tweetTopics:\n",
    "        if(value>maxValue):\n",
    "            maxValue = value\n",
    "            rightTopic = topic\n",
    "    topics.append(rightTopic)\n",
    "tweeys_data['topic'] = np.array(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportando nossas vari√°veis para pr√≥ximos usos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>weight</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.016</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>sobre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>folha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic weight    word\n",
       "0      0  0.016    news\n",
       "1      0   0.01  brasil\n",
       "2      0   0.01    fake\n",
       "3      0   0.00   sobre\n",
       "4      0   0.00   folha"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topicsWords = lda6.show_topics()\n",
    "topicsDf = []\n",
    "for topicoId, words in topicsWords:\n",
    "    for word in words.split(sep='+'):\n",
    "        topicsDf.append([topicoId,word[0:5],word[7:].strip(' ').strip('\"')])\n",
    "topicsDf = pd.DataFrame(topicsDf,columns=['topic','weight','word'])\n",
    "topicsDf.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
