# Raspagem e prepara莽茫o dos dados

## Dados do Twitter

A etapa inicial do projeto 茅 a obten莽茫o dos dados do Twitter, faremos o scraping (raspagem) dos dados, para isso utilizaremos de duas fontes, um conjunto de dados presente no Kraggle e um conjunto de dados obtido atrav茅s da API do Twitter.


```python
import pandas as pd
import tweepy as tw
import pickle as pkl
import getpass
import time
```

### Dados do Kraggle
O conjunto de dados do Kraggle _Jair Bolsonaro Twitter Data_ apresenta uma cole莽茫o de 3 mil tweets do Bolsonaro.


```python
kraggle_data = pd.read_csv("..//data//tweets//bolsonaro_tweets.csv")
kraggle_data.date = pd.to_datetime(kraggle_data.date)
kraggle_data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>date</th>
      <th>text</th>
      <th>likes</th>
      <th>retweets</th>
      <th>link</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2020-08-01</td>
      <td>- Ministro @tarcisiogdf e os 160 anos da Infra...</td>
      <td>880</td>
      <td>163</td>
      <td>https://twitter.com/jairbolsonaro/status/12895...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2020-08-01</td>
      <td>- Coletiva com o prefeito de Bag茅/RS, Divaldo ...</td>
      <td>336</td>
      <td>51</td>
      <td>https://twitter.com/jairbolsonaro/status/12895...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2020-08-01</td>
      <td>@rsallesmma </td>
      <td>442</td>
      <td>39</td>
      <td>https://twitter.com/jairbolsonaro/status/12893...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2020-08-01</td>
      <td>@Marceloscf2 @tarcisiogdf Seguimos! </td>
      <td>164</td>
      <td>22</td>
      <td>https://twitter.com/jairbolsonaro/status/12893...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2020-08-01</td>
      <td>@ItamaratyGovBr @USAID </td>
      <td>223</td>
      <td>24</td>
      <td>https://twitter.com/jairbolsonaro/status/12893...</td>
    </tr>
  </tbody>
</table>
</div>




```python
print("O per铆odo de " +  str(len(kraggle_data))+" tweets 茅 de " +  str(kraggle_data.date.min())[0:10] +" at茅 " +  str(kraggle_data.date.max())[0:10] + ".")
```

    O per铆odo de 9351 tweets 茅 de 2010-04-01 at茅 2020-08-01.
    

### Twitter API
N贸s tamb茅m podemos obter dados sobre Jair Bolsonaro, Fl谩vio Bolsonaro, Carlos Bolsonaro e Eduardo Bolsonaro da API do Twitter usando Tweepy. No entanto, o acesso 茅 permitido apenas para os 煤ltimos 3200 tweets, dessa forma, n茫o 茅 o hist贸rico completo de tweets.

<details>
<summary>Autentica莽茫o</summary>

```python
consumer_key = getpass.getpass()
```

    路路路路路路路路
    


```python
consumer_secret = getpass.getpass()
```

    路路路路路路路路
    


```python
access_token = getpass.getpass()
```

    路路路路路路路路
    


```python
access_token_secret = getpass.getpass()
```

    路路路路路路路路
    


```python
auth = tw.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)
api = tw.API(auth, wait_on_rate_limit=True)
```

</details>


```python
#requesting data from twitter
twitter_data = {}
for user in ['jairbolsonaro', 'bolsonarosp', 'flaviobolsonaro', 'carlosbolsonaro']:
    twitter_data[user] = [tweet for tweet in tw.Cursor(api.user_timeline,id=user, tweet_mode ="extended").items()]
```


```python
#saving original data
with open("..//data//tweets//brute_scrapping,pkl", "wb+") as f:
    pkl.dump(twitter_data, f)
```


```python
#script to create a dataframe from the data
date = []
text = []
user_name = []
place = []
retweets = []
favorites = []
for user in ['jairbolsonaro', 'bolsonarosp', 'flaviobolsonaro', 'carlosbolsonaro']:
    for tweet in twitter_data[user]:
        date.append(tweet._json['created_at'])
        text.append(tweet._json['full_text'])
        user_name.append(user)
        place.append(tweet._json['place'])
        retweets.append(tweet._json['retweet_count'])
        favorites.append(tweet._json['favorite_count'])
API_data = pd.DataFrame({'name': user_name, 'text': text, 'date': pd.to_datetime(date), 
                         'place': place, 'retweets': retweets, 'favorites':favorites})
API_data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>text</th>
      <th>date</th>
      <th>place</th>
      <th>retweets</th>
      <th>favorites</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>jairbolsonaro</td>
      <td>-Edif铆cio Joelma/SP, 1974.\n\n-Sgt CASSANIGA s...</td>
      <td>2020-07-27 20:51:13+00:00</td>
      <td>None</td>
      <td>3154</td>
      <td>16202</td>
    </tr>
    <tr>
      <th>1</th>
      <td>jairbolsonaro</td>
      <td>- gua para quem tem sede.\n- Liberdade para u...</td>
      <td>2020-07-27 11:10:36+00:00</td>
      <td>None</td>
      <td>8101</td>
      <td>37357</td>
    </tr>
    <tr>
      <th>2</th>
      <td>jairbolsonaro</td>
      <td>@tarcisiogdf @MInfraestrutura ю, Ministro!</td>
      <td>2020-07-26 20:18:19+00:00</td>
      <td>None</td>
      <td>1074</td>
      <td>16840</td>
    </tr>
    <tr>
      <th>3</th>
      <td>jairbolsonaro</td>
      <td>2- @MinEconomia @MinCidadania @onyxlorenzoni @...</td>
      <td>2020-07-26 15:40:39+00:00</td>
      <td>None</td>
      <td>1337</td>
      <td>6383</td>
    </tr>
    <tr>
      <th>4</th>
      <td>jairbolsonaro</td>
      <td>1- Acompanhe as redes sociais! @secomvc @fabio...</td>
      <td>2020-07-26 15:39:47+00:00</td>
      <td>None</td>
      <td>3287</td>
      <td>14836</td>
    </tr>
  </tbody>
</table>
</div>




```python
API_data.to_csv('..API_data.csv', sep = "~")
```

## Dados econ么micos

N贸s vamos coletar os dados do BACEN (Banco Central do Brasil) usando sua API. N贸s vamos utilizar as s茅ries temporais de alguns importantes indicadores econ么micos como GDP, IPCA, NPCC. O c贸digo presente neste notebook 茅 baseado no v铆deo de __C贸digo Quant - Finan莽as Quantitativas__: [COMO ACESSAR A BASE DE DADOS DO BANCO CENTRAL DO BRASIL COM PYTHON | Python para Investimentos #10](https://www.youtube.com/watch?v=7rFsu48oBn8).


```python
def query_bc(code):
    url = 'http://api.bcb.gov.br/dados/serie/bcdata.sgs.{}/dados?formato=json'.format(code)
    df = pd.read_json(url)
    df['data'] = pd.to_datetime(df['data'], dayfirst=True)
    df.set_index('data', inplace=True)
    return df
```

As s茅ries temporais escolhidas para compor o nosso conjunto de dados est茫o listadas abaixo, tabm茅m est谩 listado sua unidade e o instituto que publica o indicador:

- IPCA : ndice nacional de pre莽os ao consumidor-amplo, Var. % mensal, (IBGE). Este 铆ndice mede a varia莽茫o de pre莽os de mercado para o consumidor final e 茅 utilizado para medir a infla莽茫o.
- INPC: ndice nacional de pre莽os ao consumidor, Var. % mensal, (IBGE). Este 铆ndice mede a varia莽茫o de pre莽os da cesta de consumo da popula莽茫o assalariada com mais baixo rendimento.
- IGP-M : ndice geral de pre莽os do mercado, Var. % mensal, (FGV). Este 铆ndice mede a varia莽茫o de pre莽os atrav茅s de outros 铆ndices, do IPCA, INCC, e IPC.
- Meta SELIC : Taxa b谩sica de juros definida pelo Copom, % a.a., (Copom).
- CDI : Taxa de juros, % a.d., (Cetip). Taxa de juros para empr茅stimo entre bancos.
- PIB : Produto Interno Bruto mensal, R\$ (milh玫es), (BCB-Depec). 
- D贸lar: Taxa de c芒mbio - D贸lar americano (venda), u.m.c/US\$, (Sisbacen PTAX800).
- D铆vida p煤blica: D铆vida l铆quida do Setor P煤blico (%PIB) - Total, %, (BSB - DSTAT).
- Reserva Internacional: Reserva internacional total di谩ria, US\$ (milh玫es), (BCB - DSTAT). 
- ndice de emprego formal, (Mtb).
- PNADC: Taxa de desocupa莽茫o, %, (IBGE). 
- ndice de confian莽a do consumidor, (Fecomercio).


```python
ipca = query_bc(433) 
ipca.to_csv("..\\data\\economic_index\\ipca.csv", sep = ";")
time.sleep(5)

igpm = query_bc(189) 
igpm.to_csv("..\\data\\economic_index\\igpm.csv", sep = ";")
time.sleep(5)

inpc = query_bc(188)
inpc.to_csv("..\\data\\economic_index\\inpc.csv", sep = ";")
time.sleep(5)

selic_meta = query_bc(432)
selic_meta.to_csv("..\\data\\economic_index\\selic_meta.csv", sep = ";")
time.sleep(5)

international_reserve = query_bc(13621)
international_reserve.to_csv("..\\data\\economic_index\\international_reserve.csv", sep = ";")
time.sleep(5)

pnad = query_bc(24369)
pnad.to_csv("..\\data\\economic_index\\pnad.csv", sep = ";")
time.sleep(5)

cdi = query_bc(12)
cdi.to_csv("..\\data\\economic_index\\cdi.csv", sep = ";")
time.sleep(5)

gdp = query_bc(4385)
gdp.to_csv("..\\data\\economic_index\\gdp.csv", sep = ";")
time.sleep(5)

dollar = query_bc(1)
dollar.to_csv("..\\data\\economic_index\\dollar.csv", sep = ";")
time.sleep(5)

employment = query_bc(25239)
employment.to_csv("..\\data\\economic_index\\employment.csv", sep = ";")
time.sleep(5)

gov_debt = query_bc(4503)
gov_debt.to_csv("..\\data\\economic_index\\gov_debt.csv", sep = ";")
time.sleep(5)

consumer_confidence = query_bc(4393)
consumer_confidence.to_csv("..\\data\\economic_index\\consumer_confidence.csv", sep = ";")
time.sleep(5)
```

Vamos gerar um _dataframe_ final incluindo todas as s茅ries temporais econ么micas, note que existir茫o c茅lulas vazias pois os indicadores econ么micos apresentam frequ锚ncias diferentes, podem ser di谩rios, mensais, trimestrais ou anuais, e tamb茅m os indicadores come莽aram a ser utilizados em momentos distintos na hist贸ria.


```python
economic_time_series = pd.merge(ipca, igpm, left_index = True, right_index= True, how= 'outer')
economic_time_series = economic_time_series.merge(inpc, left_index = True, right_index= True, how= 'outer')
economic_time_series = economic_time_series.merge(selic_meta, left_index = True, right_index= True, how= 'outer')
economic_time_series = economic_time_series.merge(international_reserve, left_index = True, right_index= True, how= 'outer')
economic_time_series = economic_time_series.merge(pnad,  left_index = True, right_index= True, how= 'outer')
economic_time_series = economic_time_series.merge(cdi, left_index = True, right_index= True, how= 'outer')
economic_time_series = economic_time_series.merge(gdp, left_index = True, right_index= True, how= 'outer')
economic_time_series = economic_time_series.merge(dollar, left_index = True, right_index= True, how= 'outer')
economic_time_series = economic_time_series.merge(employment, left_index = True, right_index= True, how= 'outer')
economic_time_series = economic_time_series.merge(gov_debt, left_index = True, right_index= True, how= 'outer')
economic_time_series = economic_time_series.merge(consumer_confidence, left_index = True, right_index= True, how= 'outer')

economic_time_series.columns = ["ipca", "igpm", "inpc", "selic_meta", "international_reserve",
                                      "pnad", "cdi", "gdp", "dollar", "employment", "gov_debt", "consumer_confidence"]
economic_time_series.to_csv("..\\data\\economic_index\\economic_time_series.csv", sep = ";")
```
